{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pynvml as pynvml\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATRIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TENSOR = torch.tensor([[[ \n",
    "                        [1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]\n",
    "                      ],\n",
    "                      [ \n",
    "                        [1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]\n",
    "                      ],\n",
    "                      [ \n",
    "                        [1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]\n",
    "                      ]],\n",
    "                      ])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random tensor of size (3, 4)\n",
    "# import random\n",
    "# random_tensor = torch.ones(size=(3,224,224))\n",
    "# random_tensor[:, :, 1] = 0\n",
    "# for i in range(224):\n",
    "#     for j in range(224):\n",
    "#         random_tensor[i,j,0] = random.randint(1,100)/100\n",
    "#         random_tensor[i,j,1] = random.randint(1,100)/100\n",
    "#         random_tensor[i,j,2] = random.randint(1,100)/100\n",
    "\n",
    "# random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import ToPILImage\n",
    "# from IPython.display import Image\n",
    "# a = ToPILImage(random_tensor)\n",
    "# a = random_tensor.numpy()\n",
    "# plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor[:,0] *= zeros[:,0]\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_ten = torch.arange(1,11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor datatypes are one of the 3 big errors you'll run into with pytorch and deep learning\n",
    "1. Tensors are not the right datatype\n",
    "2. Tensors are not the right shape\n",
    "3. Tensors are not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], \n",
    "                               dtype=None, \n",
    "                               device=None, \n",
    "                               requires_grad=False)\n",
    "float_32_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_16_tensor = torch.tensor([3.0,6.0,9.0], \n",
    "#                                dtype=torch.halfy, \n",
    "#                                device=None, \n",
    "#                                requires_grad=False)\n",
    "# float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_tensor = float_32_tensor*float_16_tensor\n",
    "# merged_tensor.dtype\n",
    "# #keeps datatype of larger bit typey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_32_tensor = torch.tensor([3,6,8], dtype=torch.long)\n",
    "int_32_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(some_tensor.device)\n",
    "some_tensor = some_tensor.to('cuda:0')\n",
    "# some_tensor = some_tensor.cuda()\n",
    "print(some_tensor.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating tensors (tensor operations)\n",
    "\n",
    "*Addition\n",
    "*Subtraction\n",
    "*Multiplication (element-wise)\n",
    "*Division\n",
    "*Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a tensor \n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 10\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiply tensor by 10\n",
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide by 10\n",
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.subtract(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.divide(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(3)*10\n",
    "tensor1 = tensor1 // 1\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.rand(3)*10\n",
    "tensor2 = tensor2 // 1\n",
    "tensor2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1*tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.matmul(tensor1,tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. element-wise multiplication\n",
    "2. matrix multiplication\n",
    "\n",
    "there are two rules that performing matrix multiplication needs to satisfy:\n",
    "1. the inner dimensions must match\n",
    "(3,2) and (3,2) wont work\n",
    "(2,3) and (3,2) will work\n",
    "\n",
    "2. the resulting matrix has the shape of the outer dimensions\n",
    "(2,3) and (3,2) -> (2,2)\n",
    "(3,2) and (2,3) -> (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B) #torch.mm is the same as torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A.shape, tensor_B.shape,'',tensor_A.shape, tensor_B.T.shape,'',torch.mm(tensor_A,tensor_B.T), torch.mm(tensor_A,tensor_B.T).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A.shape, tensor_B.shape,'',tensor_A.T.shape, tensor_B.shape,'',torch.mm(tensor_A.T,tensor_B), torch.mm(tensor_A.T,tensor_B).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the min,max,mean,sum (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(x),x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "1. Reshaping - reshapes an input tensor to a defined shape\n",
    "2. View - return a view of an input tensor of a certain shape but keep the same memory as the original tensor\n",
    "3. Stacking - combine multiple tensors on top of each other. Vertical (vstack) or side by side (hstack)\n",
    "4. Squeeze - removes all `1` dimensions from a tensor\n",
    "5. Unsqueeze - add a `1` dimension to a target tensor\n",
    "6. Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = x.reshape(9,1)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.view(3,3)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack tensors on top of each other\n",
    "z = torch.rand(2,2)\n",
    "z_stacked = torch.stack([z,z])\n",
    "z, z_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2,1,2)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.squeeze()\n",
    "z.shape, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.unsqueeze(dim=1)\n",
    "z.shape,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x = torch.randint(1,11,(2,2,3))\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.permute(x, (0,2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = torch.rand(size=(5, 5, 3)) # height, width, colour channels\n",
    "\n",
    "x_permuted = x_original.permute(2,0,1)\n",
    "x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original[1,1,0] = 5\n",
    "x_original,x_original[1,1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##INdexing (selecting data from tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a tensor\n",
    "x = torch.arange(1,10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
    "x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all values of the 0 dimensions but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumPy array to tensor\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 9.0)\n",
    "tensor=torch.from_numpy(array).type(torch.float32)  #when converting from numpy to pytorch. pytorch reflects numpys default datatype which is float64 compared to pytorch (float32)\n",
    "array,tensor\n",
    "#changing numpy array doesnt mutate the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "# numpy_tensor = np.array(tensor)\n",
    "numpy_tensor = tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_tensor, numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reproducibility (trying to take random out of random)\n",
    "\n",
    "How neural networks learn:\n",
    "\n",
    "start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a random seed.\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor_a = torch.rand(3,4)\n",
    "random_tensor_b = torch.rand(3,4)\n",
    "random_tensor_a == random_tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make some random but reproducible tensors. set the random seed\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_c = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_d = torch.rand(3,4)\n",
    "random_tensor_c == random_tensor_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and Pytorch objects on the GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA+NVIDIA hardware + PyTorch working behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a tensor (Default is on CPU)\n",
    "tensor = torch.tensor([2,4,6])\n",
    "\n",
    "\n",
    "\n",
    "#Tensor not on GPU\n",
    "print(tensor, tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensors back to CPU (for example for using NumPy)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fix the GPU tensor with NumPy issue. we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00. PyTorch Fundamentals Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Documentation reading\n",
    "A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):\n",
    "\n",
    "- The documentation on torch.Tensor.\n",
    "- The documentation on torch.cuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a random tensor with shape (7, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor = torch.rand(7,7)\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor_2 = torch.rand(1,7)\n",
    "rand_tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1_mul_rand2 = rand_tensor @ rand_tensor_2.T\n",
    "rand1_mul_rand2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Set the random seed to 0 and do 2 & 3 over again.\n",
    "The output should be:\n",
    "\n",
    "(tensor([[1.8542],\n",
    "         [1.9611],\n",
    "         [2.2884],\n",
    "         [3.0481],\n",
    "         [1.7067],\n",
    "         [2.5290],\n",
    "         [1.7989]]), torch.Size([7, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8542],\n",
       "        [1.9611],\n",
       "        [2.2884],\n",
       "        [3.0481],\n",
       "        [1.7067],\n",
       "        [2.5290],\n",
       "        [1.7989]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "rand_tensor_1 = torch.rand(7,7)\n",
    "rand_tensor_2 = torch.rand(1,7)\n",
    "rand1_mul_rand2 = rand_tensor_1 @ rand_tensor_2.T\n",
    "rand1_mul_rand2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one)\n",
    "If there is, set the GPU random seed to 1234."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_SEED = 1234\n",
    "torch.cuda.manual_seed_all(CUDA_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\\\n",
    "Device: cuda\\\n",
    "(tensor([[0.0290, 0.4019, 0.2598],\\\n",
    "        [0.3666, 0.0583, 0.7006]], device='cuda:0'),\\\n",
    "tensor([[0.0518, 0.4681, 0.6738],\\\n",
    "        [0.3315, 0.7837, 0.5631]], device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0290, 0.4019, 0.2598],\n",
       "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
       " tensor([[0.0518, 0.4681, 0.6738],\n",
       "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(CUDA_SEED)\n",
    "\n",
    "gpu_tensor_1 = torch.rand(2,3).to('cuda')\n",
    "gpu_tensor_2 = torch.rand(2,3).to('cuda')\n",
    "gpu_tensor_1, gpu_tensor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\\\n",
    "The output should look like:\\\n",
    "\n",
    "(tensor([[0.3647, 0.4709],\\\n",
    "         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3647, 0.4709],\n",
       "        [0.5184, 0.5617]], device='cuda:0')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_gpu_tensors = gpu_tensor_1 @ gpu_tensor_2.T\n",
    "matmul_gpu_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Find the maximum and minimum values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_gpu_tensors.max(),matmul_gpu_tensors.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find the maximum and minimum index values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_gpu_tensors.argmax(), matmul_gpu_tensors.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\\\n",
    "The output should look like:\\\n",
    "\n",
    "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\\\n",
    "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\\\n",
    "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\\\n",
    "        0.8513]) torch.Size([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "tensor = torch.rand(1,1,1,10)\n",
    "new_tensor = tensor.squeeze()\n",
    "\n",
    "print(tensor,tensor.shape)\n",
    "print(new_tensor, new_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastaicourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
